---
title: "3/8/2023"
output: html_document
date: "2023-03-08"
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(kableExtra)
library(ggpubr)
library(rstatix) # use anova_test function 
library(DT)
set.seed(123)
```


```{r, echo=F, warning=F, message=F}
pvalue_adjust=function(p_value)
{
  p_value_adjust=numeric()
for (i in 1:length(p_value))
{
  if (is.na(p_value[i])==T)
    p_value_adjust[i]=p_value[i]
  if (is.na(p_value[i])==F & p_value[i]<0.0001)
    p_value_adjust[i]="<0.0001"
  if (is.na(p_value[i])==F & p_value[i]>0.0001)
    p_value_adjust[i]=round(p_value[i],4)
}
  return(p_value_adjust)
}
############### summary statistics for continuous variable 
summary_statistics=function(data)
{  # each column is one variable, and row one subject 
  
  variables=colnames(data)
num_sample=numeric()
Mean=numeric()
SD=numeric()
SE=numeric()
range_min=numeric()
range_max=numeric()
for (i in 1:ncol(data))
{
  observation=data[,i]
  observation=observation[!is.na(observation)]
  num_sample[i]=length(observation)
  Mean[i]=round(mean(observation),4)
  SD[i]=round(sd(observation),4)
  SE[i]=round(SD[i]/sqrt(num_sample[i]),4)
  range_min[i]=round(min(observation),4)
  range_max[i]=round(max(observation),4)
}

summary_data=data.frame(materials=variables, num_sample=num_sample, Mean=Mean, SD=SD, SE=SE, Range_low=range_min, Range_upper=range_max)

summary_data%>%
datatable(extensions = 'Buttons',
            options = list(dom = 'Blfrtip',
                           buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
                           lengthMenu = list(c(10,25,50,-1),
                                             c(10,25,50,"All"))))
  
 return(summary_data) 
}
```

```{r, echo=F, message=F, warning=F}
data=as_tibble(read.csv("C:\\Shengtong\\Research\\AllCollaboration\\2023\\202301\\Christos\\Data Collection sheet - Final.csv", header=T))
```

## use R package [BUGSnet](https://bugsnetsoftware.github.io/) 

```{r, echo=F, message=F, warning=F, eval=F}
#install.packages(c("remotes", "knitr"))
remotes::install_github("audrey-b/BUGSnet@v1.1.0", upgrade = TRUE, build_vignettes = TRUE, dependencies = TRUE)

#remotes::install_github("audrey-b/BUGSnet@v1.1.0", upgrade = TRUE, build_vignettes = TRUE, dependencies = TRUE)
```
## [MetaStan](https://cran.r-project.org/web/packages/MetaStan/MetaStan.pdf)

## multinma 

```{r, echo=F, message=F, warning=F}
#install.packages("multinma")
library(multinma)
head(parkinsons)

```

###  [Analysis of arm-based data](https://dmphillippo.github.io/multinma/articles/example_parkinsons.html)

```{r, echo=F, message=F, warning=F}
arm_net <- set_agd_arm(parkinsons, 
                      study = studyn,
                      trt = trtn,
                      y = y, 
                      se = se,
                      sample_size = n) # use trt_ref to set reference treatment 
arm_net
plot(arm_net, weight_edges = TRUE, weight_nodes = TRUE)
```

#### fixed effect meta-analysis


```{r, echo=F, message=F, warning=F}
summary(normal(scale = 100))

arm_fit_FE <- nma(arm_net, 
                  trt_effects = "fixed",
                  prior_intercept = normal(scale = 100),
                  prior_trt = normal(scale = 10))
#> Note: Setting "4" as the network reference treatment.
#> 
#> 
#> arm_fit_FE
#> A fixed effects NMA with a normal likelihood (identity link).
#> Inference for Stan model: normal.
#> 4 chains, each with iter=2000; warmup=1000; thin=1; 
#> post-warmup draws per chain=1000, total post-warmup draws=4000.
#> 
#>       mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat
#> d[1]  0.53    0.01 0.46  -0.38  0.21  0.53  0.84  1.42  1624    1
#> d[2] -1.29    0.01 0.50  -2.27 -1.63 -1.29 -0.95 -0.30  1731    1
#> d[3]  0.03    0.01 0.32  -0.60 -0.18  0.04  0.24  0.66  2253    1
#> d[5] -0.30    0.00 0.21  -0.71 -0.44 -0.30 -0.17  0.10  2401    1
#> lp__ -6.63    0.06 2.35 -12.04 -7.99 -6.28 -4.92 -3.10  1719    1
#> 
#> Samples were drawn using NUTS(diag_e) at Mon Aug 29 22:15:09 2022.
#> For each parameter, n_eff is a crude measure of effective sample size,
#> and Rhat is the potential scale reduction factor on split chains (at 
#> convergence, Rhat=1).
#> 

print(arm_fit_FE, pars = c("d", "mu")) # mu: study specific intercept; d_k treatment effects 
plot_prior_posterior(arm_fit_FE)
```
* there are 7 studies and 5 treatments with 4 as reference 



#### Random effects meta-analysis


```{r, echo=F, message=F, warning=F}
summary(normal(scale = 100))
summary(half_normal(scale = 5))
arm_fit_RE <- nma(arm_net, 
                  seed = 379394727,
                  trt_effects = "random",
                  prior_intercept = normal(scale = 100),
                  prior_trt = normal(scale = 100),
                  prior_het = half_normal(scale = 5),
                  adapt_delta = 0.99)


pairs(arm_fit_RE, pars = c("mu[4]", "d[3]", "delta[4: 3]", "tau"))
arm_fit_RE
```

## [metafor](https://www.wvbauer.com/lib/exe/fetch.php/talks:2019_viechtbauer_lsp_ma_longitudinal.pdf)

```{r, echo=F, message=F, warning=F}
 dat <- data.frame( 
   study = c("Jones et al. (1998)", "Lewis et al. (2004)",
 "Grant et al. (2006)", "Berry et al. (2013)",
 "Nolan et al. (2015)", "Clark et al. (2016)"),
 age1 = c( 20, 20, 20, 20, 20, 20),
 age2 = c( 40, 40, 40, 40, 40, 40),
 mean1 = c(13.4, 2.9, 55.8, 19.2, 6.6, 10.1),
 mean2 = c(15.1, 3.6, 61.2, 18.8, 8.5, 10.2),
 sd1 = c( 4.8, 1.2, 22.3, 2.9, 3.4, 3.8),
 n = c( 78, 22, 188, 35, 54, 112),
 r = c( .32, .29, .28, .41, .35, .19))

library(metafor)
 # calculate standardized mean changes (with raw score standardization)
 dat <- escalc(measure="SMCR", m1i=mean2, m2i=mean1, # "SMCR" for the standardized mean change using raw score standardization
 sd1i=sd1, ni=n, ri=r, data=dat, slab=study)

 # fit random-effects model and examine results
 res <- rma(yi, vi, data=dat)
 res 
 
 
  # create a forest and funnel plot side-by-side
 # note: the plots below have been customized a bit
 par(mfrow=c(1,2))
 forest(res)
 funnel(res)
```

## Reference 

* [Network meta-analysis: application and practice using R software](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6635665/pdf/epih-41-e2019013.pdf)

* [bayesmeta](https://cran.r-project.org/web/packages/bayesmeta/vignettes/Roever2020-bayesmeta.pdf)

* [multinma](https://dmphillippo.github.io/multinma/articles/vignette_overview.html)

* [metafor](https://www.wvbauer.com/lib/exe/fetch.php/talks:2019_viechtbauer_lsp_ma_longitudinal.pdf); longitudinal meta analysis


## Sample size determination 


 * [Olsen paper](https://pubmed.ncbi.nlm.nih.gov/28215182/) 


```{r, echo=T, message=F, warning=F}

d=29-9; # use the median difference as mean difference  
SD=18/1.35 # use SD=IQR/1.35 
power.t.test(power = .90, delta = d, alternative = "two.sided", sig.level=0.05, sd=SD)
```

* [Santos paper](https://pubmed.ncbi.nlm.nih.gov/34031888/)

```{r, echo=T, message=F, warning=F}

d=4-1; #  mean difference  
SD=1.48-1.21 # SD difference 
power.t.test(power = .90, delta = d, alternative = "two.sided", sig.level=0.05, sd=SD)
```
