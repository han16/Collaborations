---
title: "3/8/2023"
output: html_document
date: "2023-03-08"
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(kableExtra)
library(ggpubr)
library(rstatix) # use anova_test function 
library(DT)
library(readxl)
library(multinma)
library(meta)
set.seed(123)
```



```{r, echo=F, warning=F, message=F}
pvalue_adjust=function(p_value)
{
  p_value_adjust=numeric()
for (i in 1:length(p_value))
{
  if (is.na(p_value[i])==T)
    p_value_adjust[i]=p_value[i]
  if (is.na(p_value[i])==F & p_value[i]<0.0001)
    p_value_adjust[i]="<0.0001"
  if (is.na(p_value[i])==F & p_value[i]>0.0001)
    p_value_adjust[i]=round(p_value[i],4)
}
  return(p_value_adjust)
}
############### summary statistics for continuous variable 
summary_statistics=function(data)
{  # each column is one variable, and row one subject 
  
  variables=colnames(data)
num_sample=numeric()
Mean=numeric()
SD=numeric()
SE=numeric()
range_min=numeric()
range_max=numeric()
for (i in 1:ncol(data))
{
  observation=data[,i]
  observation=observation[!is.na(observation)]
  num_sample[i]=length(observation)
  Mean[i]=round(mean(observation),4)
  SD[i]=round(sd(observation),4)
  SE[i]=round(SD[i]/sqrt(num_sample[i]),4)
  range_min[i]=round(min(observation),4)
  range_max[i]=round(max(observation),4)
}

summary_data=data.frame(materials=variables, num_sample=num_sample, Mean=Mean, SD=SD, SE=SE, Range_low=range_min, Range_upper=range_max)

summary_data%>%
datatable(extensions = 'Buttons',
            options = list(dom = 'Blfrtip',
                           buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
                           lengthMenu = list(c(10,25,50,-1),
                                             c(10,25,50,"All"))))
  
 return(summary_data) 
}


multiplesheets <- function(fname) {
   
  # getting info about all excel sheets
  sheets <- readxl::excel_sheets(fname)
  tibble <- lapply(sheets, function(x) readxl::read_excel(fname, sheet = x))
  data_frame <- lapply(tibble, as.data.frame)
    
  # assigning names to data frames
  names(data_frame) <- sheets
    
  # print data frame
  print(data_frame)
}


```

```{r, echo=F, message=F, warning=F, results=F}
#data1=as_tibble(read.csv("C:\\Shengtong\\Research\\AllCollaboration\\2023\\202301\\Christos\\Data Collection sheet - Final.csv", header=T))
#data=as_tibble(read.csv("C:\\Shengtong\\Research\\AllCollaboration\\2023\\202301\\Christos\\Data for VAS 1h.csv", header=T))
data=multiplesheets("C:\\Shengtong\\Research\\AllCollaboration\\2023\\202301\\Christos\\DataforVAS_08052023.xlsx")
```


## one hour 

### sample data 

```{r, echo=F, message=F, warning=F}
data_1hour=data$`OneHour`[,c(1,3,8, 5,7)]
data_1hour_full=as_tibble(data_1hour[complete.cases(data_1hour), ]) 
colnames(data_1hour_full)=c("study", "treatment", "n", "mean", "sd")

data_1hour_full%>%
datatable(extensions = 'Buttons',
          caption = "one hour", 
            options = list(dom = 'Blfrtip',
                           buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
                           lengthMenu = list(c(10,25,50,-1),
                                             c(10,25,50,"All"))))

```





### forest plot 

```{r, echo=F, message=F, warning=F}
##### https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/forest.html


#data(Fleiss1993cont)

#m1 <- metacont(n.psyc, mean.psyc, sd.psyc, n.cont, mean.cont, sd.cont,
 # data = Fleiss1993cont, sm = "SMD")
#m1
#forest(m1)

######## manually create the data matrix 
study_data=matrix(nrow=11, ncol=6)
study_data[1,]=c(as.numeric(data_1hour_full[1,3:5]), as.numeric(data_1hour_full[2,3:5]))
study_data[2,]=c(as.numeric(data_1hour_full[3,3:5]), as.numeric(data_1hour_full[4,3:5]))
study_data[3,]=c(as.numeric(data_1hour_full[6,3:5]), as.numeric(data_1hour_full[5,3:5]))
study_data[4,]=c(as.numeric(data_1hour_full[7,3:5]), as.numeric(data_1hour_full[5,3:5]))
study_data[5,]=c(as.numeric(data_1hour_full[8,3:5]), as.numeric(data_1hour_full[9,3:5]))
study_data[6,]=c(as.numeric(data_1hour_full[10,3:5]), as.numeric(data_1hour_full[11,3:5]))
study_data[7,]=c(as.numeric(data_1hour_full[12,3:5]), as.numeric(data_1hour_full[14,3:5]))
study_data[8,]=c(as.numeric(data_1hour_full[13,3:5]), as.numeric(data_1hour_full[14,3:5]))
study_data[9,]=c(as.numeric(data_1hour_full[15,3:5]), as.numeric(data_1hour_full[17,3:5]))
study_data[10,]=c(as.numeric(data_1hour_full[16,3:5]), as.numeric(data_1hour_full[17,3:5]))
study_data[11,]=c(as.numeric(data_1hour_full[18,3:5]), as.numeric(data_1hour_full[19,3:5]))
study=c("Pearlman, B.", "Pereira, G.", "Pilatti, G.", "Pilatti, G.", "Santos, B.",  "Santos, B.", "Steffens, J 2011", "Steffens, J 2011", "Steffens, J 2011 @", "Steffens, J 2011 @", "Trombelli, L.")

data_meta=data.frame(study=study,samplesize_exp=study_data[,1], mean_exp=study_data[,2], sd_exp=study_data[,3], samplesize_contr=study_data[,4], mean_contr=study_data[,5], sd_contr=study_data[,6] )
colnames(study_data)=c("samplesize_exp", "mean_exp", "sd_exp", "samplesize_contr", "mean_contr", "sd_contr")
rownames(study_data)=study

data_meta=data.frame(study_data)

m1 <- metacont(samplesize_exp, mean_exp, sd_exp, samplesize_contr, mean_contr, sd_contr,
  data = data_meta, sm = "SMD")
m1
forest.meta(m1, layout="JAMA")


data_meta%>%
datatable(extensions = 'Buttons',
          caption = "one hour", 
            options = list(dom = 'Blfrtip',
                           buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
                           lengthMenu = list(c(10,25,50,-1),
                                             c(10,25,50,"All"))))

```


* For an individual study, a square with treatment estimate in the center and confidence interval as line extending either side of the square


* For meta-analysis results, a diamond with treatment estimate in the center and right and left side corresponding to lower and upper confidence limits

* heterogeneity (null hypothesis: all studies estimate the same effect) is measured by Cochranâ€™s Q, which is calculated as the weighted sum of squared differences between individual study effects and the pooled effect across studies, following $\chi^2$ distribution with number of studies-1 DF. 

* $I^2$ statistic describes the percentage of variation across studies that is due to heterogeneity rather than chance
[more details](https://www.statsdirect.com/help/meta_analysis/heterogeneity.htm#:~:text=Heterogeneity%20in%20meta%2Danalysis%20refers,the%20inconsistency%20of%20studies'%20results). 

* [SMD interpretations](https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-14-30#:~:text=Firstly%2C%20the%20SMD%20can%20be,a%20large%20effect%20%5B2%5D.)

```{r, echo=T, message=F, warning=F}
n1=63; s1=21; n2=61; s2=25
# Calculate s_pooled
s_pooled <- sqrt(  # s_pooled is pooled standard deviation
  (((n1-1)*s1^2) + ((n2-1)*s2^2))/
    ((n1-1)+(n2-1))
)

# Calculate the standard error
se <- s_pooled*sqrt((1/n1)+(1/n2))
#se

mean1=10; mean2=19
(mean1-mean2)/s_pooled  # this is SMD 
```



### network meta-analysis 

```{r, echo=F, message=F, warning=F}
library(netmeta)
########### install package dmetar 
#if (!require("devtools")) {
#  install.packages("devtools")
#}
#devtools::install_github("MathiasHarrer/dmetar")
library(dmetar)

data(TherapyFormats)

#head(TherapyFormats[1:5])

```



```{r, echo=F, eval=F}

### Analysis of arm-based data

```{r, echo=F, message=F, warning=F, eval=F}
data_arm=data %>% select(studyn, treatmentn, mean..y., standard.error..se., sample.size..n.) %>% drop_na()
data_arm$treatmentn[9]="placebo" # rename "placebo 1", "placebo 2" as placebo 
#data_arm$treatmentn[11]="placebo"
data_arm=data_arm[-11,] # remove "placebo 2" to avoid two occurances of placebos in study 9

data_arm%>%
datatable(extensions = 'Buttons',
          caption = "sub-data for arm-based analysis", 
            options = list(dom = 'Blfrtip',
                           buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
                           lengthMenu = list(c(10,25,50,-1),
                                             c(10,25,50,"All"))))

arm_net <- set_agd_arm(data_arm, 
                      study = studyn,
                      trt = treatmentn,
                      y = mean..y., 
                      se = standard.error..se.,
                      sample_size = sample.size..n.) # use trt_ref to set reference treatment 
arm_net
plot(arm_net, weight_edges = TRUE, weight_nodes = TRUE)



* rename "placebo 1" as placebo 
* remove "placebo 2"
* each node is one treatment, 7 treatments (nodes) in total. 
* edge between two nodes indicates these two treatments are in one study, and edge width indicates how many studies involving these treatment,  e.g. 3 studies involve placebo and ibuprofen 
* node size indicates the sample size 






#### fixed effect meta-analysis


```{r, echo=F, message=F, warning=F, results=F, eval=F}
summary(normal(scale = 100))

arm_fit_FE <- nma(arm_net, 
                  trt_effects = "fixed",
                  prior_intercept = normal(scale = 100),
                  prior_trt = normal(scale = 10))
#> 
#> 
#> arm_fit_FE
#> A fixed effects NMA with a normal likelihood (identity link).
#> Inference for Stan model: normal.
#> 4 chains, each with iter=2000; warmup=1000; thin=1; 
#> post-warmup draws per chain=1000, total post-warmup draws=4000.
#> 
#>       mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat
#> d[1]  0.53    0.01 0.46  -0.38  0.21  0.53  0.84  1.42  1624    1
#> d[2] -1.29    0.01 0.50  -2.27 -1.63 -1.29 -0.95 -0.30  1731    1
#> d[3]  0.03    0.01 0.32  -0.60 -0.18  0.04  0.24  0.66  2253    1
#> d[5] -0.30    0.00 0.21  -0.71 -0.44 -0.30 -0.17  0.10  2401    1
#> lp__ -6.63    0.06 2.35 -12.04 -7.99 -6.28 -4.92 -3.10  1719    1
#> 
#> Samples were drawn using NUTS(diag_e) at Mon Aug 29 22:15:09 2022.
#> For each parameter, n_eff is a crude measure of effective sample size,
#> and Rhat is the potential scale reduction factor on split chains (at 
#> convergence, Rhat=1).
#> 

print(arm_fit_FE, pars = c("d", "mu")) # mu: study specific intercept; d_k treatment effects 
plot_prior_posterior(arm_fit_FE)


* use $N(0,100^2)$ prior distributions for the treatment effects `d[k]`
 and study-specific intercepts `mu[j]`
* `placebo` is the reference treatment 
* `d[k]` treatment effects
* `mu[j]` study specific intercepts 



#### relative effects against placebo 

```{r, echo=F, message=F, warning=F, eval=F}
(arm_releff_FE <- relative_effects(arm_fit_FE, trt_ref = "placebo"))
plot(arm_releff_FE, ref_line = 0)


* each horizontal line of every treatment  visualizes 5 summary statistics 2.5%,25%, 50%, 75%, 97.5%. 

#### treatment ranking 

```{r, echo=F, message=F, warning=F, eval=F}
(arm_ranks <- posterior_ranks(arm_fit_FE))
plot(arm_ranks)

#(arm_rankprobs <- posterior_rank_probs(arm_fit_FE))
#plot(arm_rankprobs)


* rank the treatments by `d[k]`, the larger mean, the higher rank. ibuprofen > nimesilide > dexamethasone 8mg > ketorolac 10mg > celecoxib 200mg > 
placebo > dexamethasone 4mg 


```{r, echo=F, message=F, warning=F, eval=F}
 dat <- data.frame( 
   study = c("Jones et al. (1998)", "Lewis et al. (2004)",
 "Grant et al. (2006)", "Berry et al. (2013)",
 "Nolan et al. (2015)", "Clark et al. (2016)"),
 age1 = c( 20, 20, 20, 20, 20, 20),
 age2 = c( 40, 40, 40, 40, 40, 40),
 mean1 = c(13.4, 2.9, 55.8, 19.2, 6.6, 10.1),
 mean2 = c(15.1, 3.6, 61.2, 18.8, 8.5, 10.2),
 sd1 = c( 4.8, 1.2, 22.3, 2.9, 3.4, 3.8),
 n = c( 78, 22, 188, 35, 54, 112),
 r = c( .32, .29, .28, .41, .35, .19))

library(metafor)
 # calculate standardized mean changes (with raw score standardization)
 dat <- escalc(measure="SMCR", m1i=mean2, m2i=mean1, # "SMCR" for the standardized mean change using raw score standardization
 sd1i=sd1, ni=n, ri=r, data=dat, slab=study)

 # fit random-effects model and examine results
 res <- rma(yi, vi, data=dat)
 res 
 
 
  # create a forest and funnel plot side-by-side
 # note: the plots below have been customized a bit
 par(mfrow=c(1,2))
 forest(res)
 funnel(res)


## Reference 

* [BUGSnet](https://bugsnetsoftware.github.io/) 

*  [MetaStan](https://cran.r-project.org/web/packages/MetaStan/MetaStan.pdf)

* [Network meta-analysis: application and practice using R software](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6635665/pdf/epih-41-e2019013.pdf)

* [bayesmeta](https://cran.r-project.org/web/packages/bayesmeta/vignettes/Roever2020-bayesmeta.pdf)

* [multinma](https://dmphillippo.github.io/multinma/articles/vignette_overview.html)

* [metafor](https://www.wvbauer.com/lib/exe/fetch.php/talks:2019_viechtbauer_lsp_ma_longitudinal.pdf); longitudinal meta analysis


```




## Sample size determination 


 * [Olsen paper](https://pubmed.ncbi.nlm.nih.gov/28215182/) 


```{r, echo=T, message=F, warning=F}

mean_difference=seq(1,20); # use the median difference as mean difference  
SD=18/1.35 # use SD=IQR/1.35 
sample_size=numeric()
for (i in 1:length(mean_difference))
  sample_size[i]=round(power.t.test(power = .80, delta = mean_difference[i], alternative = "two.sided", sig.level=0.05, sd=SD)$n)

data.frame(mean_difference, sample_size)%>%
datatable(extensions = 'Buttons',
          caption="mean difference vs sample size",
            options = list(dom = 'Blfrtip',
                           buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
                           lengthMenu = list(c(10,25,50,-1),
                                             c(10,25,50,"All"))))

```
* sample size with varying mean difference, given 80\% power. 


* [Santos paper](https://pubmed.ncbi.nlm.nih.gov/34031888/)

```{r, echo=T, message=F, warning=F}

mean_difference=seq(0.1,4, by=0.5); #  mean difference  
SD=max(1.48,1.21) # use SD maximum  
sample_size=numeric()
for (i in 1:length(mean_difference))
  sample_size[i]=round(power.t.test(power = .80, delta = mean_difference[i], alternative = "two.sided", sig.level=0.05, sd=SD)$n)

data.frame(mean_difference, sample_size)%>%
datatable(extensions = 'Buttons',
          caption="mean difference vs sample size",
            options = list(dom = 'Blfrtip',
                           buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
                           lengthMenu = list(c(10,25,50,-1),
                                             c(10,25,50,"All"))))
```
 * sample size with varying mean difference, given 80\% power.
 
 